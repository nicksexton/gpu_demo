{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras for GPU-accelerated training of neural nets\n",
    "## CIFAR10/100 using Keras inbuild imagedatagenerator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example model\n",
    "\n",
    "As an example let's use a conv net doing supervised image classification on the CIFAR10 dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to specify GPUs for training\n",
    "- use CUDA_VISIBLE_DEVICES environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to \"-1\" to disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras.backend as K\n",
    "# config = tf.ConfigProto(device_count={\"CPU\": 8})\n",
    "# K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, #False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False, #False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False, #False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False, #False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model (with GPU)\n",
    "\n",
    "Multiprocessing here refers to using multiple CPU threads to do the image preprocessing\n",
    "\n",
    "Check out the effect that changing the parameters for the image data generator pipeline has on GPU load.\n",
    "\n",
    "In particular, setting use_multiprocessing to False makes for a dramatic slowdown\n",
    "\n",
    "*health warning* You should take the warning about Keras ImageDataGenerators not being thread safe seriously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 42s 873ms/step - loss: 1.2713 - acc: 0.5465 - val_loss: 1.1937 - val_acc: 0.5740\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 41s 860ms/step - loss: 1.2639 - acc: 0.5503 - val_loss: 1.1744 - val_acc: 0.5868\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 41s 862ms/step - loss: 1.2657 - acc: 0.5488 - val_loss: 1.1461 - val_acc: 0.5976\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 41s 847ms/step - loss: 1.2487 - acc: 0.5582 - val_loss: 1.1330 - val_acc: 0.5993\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 41s 847ms/step - loss: 1.2461 - acc: 0.5578 - val_loss: 1.1963 - val_acc: 0.5780\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 41s 862ms/step - loss: 1.2321 - acc: 0.5617 - val_loss: 1.1941 - val_acc: 0.5742\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 41s 861ms/step - loss: 1.2379 - acc: 0.5596 - val_loss: 1.1170 - val_acc: 0.6077\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 41s 861ms/step - loss: 1.2275 - acc: 0.5651 - val_loss: 1.0846 - val_acc: 0.6222\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 40s 836ms/step - loss: 1.2235 - acc: 0.5642 - val_loss: 1.1617 - val_acc: 0.5857\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 41s 859ms/step - loss: 1.2163 - acc: 0.5660 - val_loss: 1.0767 - val_acc: 0.6202\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 41s 862ms/step - loss: 1.2089 - acc: 0.5727 - val_loss: 1.1448 - val_acc: 0.5991\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 41s 863ms/step - loss: 1.2045 - acc: 0.5742 - val_loss: 1.1721 - val_acc: 0.5853\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 41s 864ms/step - loss: 1.2066 - acc: 0.5738 - val_loss: 1.0954 - val_acc: 0.6191\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 41s 863ms/step - loss: 1.1982 - acc: 0.5757 - val_loss: 1.0766 - val_acc: 0.6199\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 42s 865ms/step - loss: 1.1932 - acc: 0.5771 - val_loss: 1.0847 - val_acc: 0.6177\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 41s 859ms/step - loss: 1.1816 - acc: 0.5825 - val_loss: 1.1521 - val_acc: 0.5921\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 40s 833ms/step - loss: 1.1836 - acc: 0.5821 - val_loss: 1.0767 - val_acc: 0.6245\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 41s 864ms/step - loss: 1.1750 - acc: 0.5850 - val_loss: 1.0471 - val_acc: 0.6334\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 41s 857ms/step - loss: 1.1725 - acc: 0.5872 - val_loss: 1.0420 - val_acc: 0.6375\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 41s 858ms/step - loss: 1.1612 - acc: 0.5904 - val_loss: 1.0266 - val_acc: 0.6425\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 41s 858ms/step - loss: 1.1645 - acc: 0.5881 - val_loss: 1.0993 - val_acc: 0.6124\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 41s 858ms/step - loss: 1.1534 - acc: 0.5930 - val_loss: 1.0841 - val_acc: 0.6201\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 41s 858ms/step - loss: 1.1617 - acc: 0.5903 - val_loss: 1.0844 - val_acc: 0.6170\n",
      "Epoch 24/100\n",
      "32/48 [===================>..........] - ETA: 13s - loss: 1.1483 - acc: 0.5926"
     ]
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                batch_size=batch_size),\n",
    "                    steps_per_epoch=int(x_train.shape[0]/batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    max_queue_size=16,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
